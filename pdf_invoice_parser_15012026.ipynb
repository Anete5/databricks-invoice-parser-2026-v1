{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2a74a2c-230f-4350-a5d0-325d2052045c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Invoice Parsing Notebook\n",
    "The notebook automatically extracts structured data from advertising invoices (PDFs) issued by advertising platforms like Meta, Google Ads, Microsoft Ads, and DerbySoft. \n",
    "<br>\n",
    "After extraction, it reads the data into a table for further querying/transformations (optional), and it also sends the extracted data as a file attachment directly to the specified email address (optional). Additionally, the data can be downloaded directly from the notebook's Output window.\n",
    "<br>\n",
    "<br>\n",
    "### **About the solution** <br>\n",
    "\n",
    "The code implements a robust, flexible invoice parsing system capable of extracting structured data from diverse invoice formats, including tables with missing headers, multiple currency and decimal formats, and vendor-specific variations. The solution intelligently identifies the required attributes, such as invoice number, invoice currency, advertising company, account name/ID; it normalizes amounts, and optionally filters summary or regulatory rows, reducing manual processing time and error risk. Its design is modular and production-ready, enabling easy adaptation to new invoice layouts without rewriting core logic.\n",
    "\n",
    "### **Usage**  \n",
    "- The notebook can be run in any Databricks environment (including Free Edition). Ensure the `ai_parse_document` function is available in your Databricks environment.\n",
    "- Modify the `INVOICE_KEYWORDS`, `CURRENCY_CODES`, `ACCOUNT_KEYWORDS`, `MANUAL_OVERRIDES`, `VENDOR_PATTERNS`,`ROW_EXCLUDE_KEYWORDS`, `ROW_OPTIONAL_EXCLUDE_KEYWORDS`, `EXACT_EXCLUDE`, `HOTEL_DESC_KEYWORDS`,`DESC_KEYWORDS`,`AMT_KEYWORDS` lists to customize the code to fit your needs. \n",
    "- To improve OCR accuracy, you can convert to higher resolution PDFs in a local environment (e.g. PyCharm) or other, install the latest [Poppler library for Windows](https://github.com/oschwartz10612/poppler-windows/releases/), then import the _pdf2image_ module and run your code. Additionally, run `%pip install pdf2image` in Databricks before executing the notebook with your higher resolution files. To check DPI information, you can follow [this link](https://apitemplate.io/pdf-tools/free-pdf-dpi-analyzer/).\n",
    "\n",
    "### **Additional notes**<br>\n",
    "\n",
    "`ai_parse_document` can be cluster-dependent.\n",
    "Different Databricks clusters may have different versions of the AI runtime or model. Even a different cluster in the same workspace can have slightly different parsing behavior, especially with PDFs.  Small differences in how the AI runtime handles tables, whitespace, fonts, or line breaks - all of this can lead to slightly different outputs.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32452901-6f2b-4f8a-a9e0-ad17205bb4e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3dcde30-6919-4119-86f0-d6627e959cee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Create a Volume and upload the files**\n",
    "<br>\n",
    "Use the UI or Notebook to create the volume and upload the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16bcaf5c-a94c-46e9-9fb5-c716cbac22d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Convert the PDFs (Optional)**<br>Install Poppler library<br>Install the module<br>Run the code in your chosen environment to convert to DPI 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7abdaab7-0906-43d0-8a2d-deca52a5a132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Install the pdf2image module in Databricks (Optional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1571df0c-cec4-4928-8105-19c539ea7da9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check if module installed"
    }
   },
   "outputs": [],
   "source": [
    "# Check if the module is installed already\n",
    "try:\n",
    "    import pdf2image\n",
    "    print(\"pdf2image is installed\")\n",
    "except ImportError:\n",
    "    print(\"pdf2image is NOT installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9207c520-7de1-4c27-9cc4-3fe122a8a851",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install pdf2image"
    }
   },
   "outputs": [],
   "source": [
    "# Run the following command to install the module\n",
    "%pip install pdf2image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6427d8b1-e03c-414b-a8e6-ab7373d7a479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Execute the code**<br>Modify the necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9c5cf0c-45a8-411a-87fa-94a550d97631",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Parse and extract"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code and its underlying logic are the intellectual property of Anete Mikelsone.\n",
    "Unauthorized use, modification of core logic, or redistribution is prohibited without explicit permission.\n",
    "\n",
    "The code may be used internally by the team for internal business purposes, provided that:\n",
    "- The original author is credited\n",
    "- The code is not redistributed publicly\n",
    "\n",
    "Configuration-level adjustments (such as modifying keyword lists, vendor names, or filtering parameters)\n",
    "are permitted for internal use and do not constitute modification of the core logic.\n",
    "\n",
    "Created by: Anete Mikelsone\n",
    "Date: January 13, 2026\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark.sql.functions import udf, explode, col, expr\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType\n",
    "import re\n",
    "\n",
    "# =========================\n",
    "# INVOICE NUMBER EXTRACTION\n",
    "# =========================\n",
    "\n",
    "# Put \"invoice #\" as the first keyword because Meta has \"Invoice number must be referenced...\" phrase\n",
    "INVOICE_KEYWORDS = [\n",
    "    \"invoice #\",\n",
    "    \"invoice number\",\n",
    "    \"rechnungsnummer\",\n",
    "    \"invoice no\",\n",
    "    \"rechnung nr\"\n",
    "]\n",
    "\n",
    "\n",
    "def extract_invoice_number(elements):\n",
    "    if not elements or not isinstance(elements, list):\n",
    "        return None\n",
    "\n",
    "    # Normalize elements into plain dicts\n",
    "    norm_elements = []\n",
    "    for el in elements:\n",
    "        if isinstance(el, dict):\n",
    "            norm_elements.append(el)\n",
    "        else:\n",
    "            norm_elements.append(el.asDict())\n",
    "\n",
    "    for i, el in enumerate(norm_elements):\n",
    "        content = el.get(\"content\")\n",
    "        if not content:\n",
    "            continue\n",
    "\n",
    "        content_lower = content.lower()\n",
    "\n",
    "        for kw in INVOICE_KEYWORDS:\n",
    "            if kw not in content_lower:\n",
    "                continue\n",
    "\n",
    "            # Combine current + next element in case it's split between two elements\n",
    "            combined = content\n",
    "            if i + 1 < len(norm_elements):\n",
    "                combined += \" \" + (norm_elements[i + 1].get(\"content\") or \"\")\n",
    "\n",
    "            # Strict regex - MUST have a keyword + separator\n",
    "            match = re.search(\n",
    "                rf\"{re.escape(kw)}\\s*[:#\\-]\\s*([A-Za-z0-9\\-]+)\",\n",
    "                combined,\n",
    "                flags=re.IGNORECASE\n",
    "            )\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "\n",
    "            # Relaxed regex - allows no separator, but MUST contain digits\n",
    "            match = re.search(\n",
    "                rf\"{re.escape(kw)}.*?([A-Za-z]{{0,3}}\\d{{5,}})\",\n",
    "                combined,\n",
    "                flags=re.IGNORECASE\n",
    "            )\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "\n",
    "    return None\n",
    "\n",
    "invoice_udf = udf(extract_invoice_number, StringType())\n",
    "\n",
    "# =========================\n",
    "# CURRENCY CODE EXTRACTION\n",
    "# =========================\n",
    "\n",
    "CURRENCY_CODES = [\"EUR\", \"USD\", \"GBP\", \"CHF\", \"CAD\", \"AUD\", \"JPY\"]\n",
    "\n",
    "INLINE_CURRENCY_REGEX = re.compile(\n",
    "    r\"\\b(EUR|USD|GBP|CHF|CAD|AUD|JPY)\\b|\\((EUR|USD|GBP|CHF|CAD|AUD|JPY)\\)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "\n",
    "def extract_currency(elements):\n",
    "    if not elements:\n",
    "        return None\n",
    "\n",
    "    texts = []\n",
    "    for el in elements:\n",
    "        try:\n",
    "            text = el[\"content\"]\n",
    "        except Exception:\n",
    "            text = None\n",
    "\n",
    "        if text:\n",
    "            texts.append(text)\n",
    "\n",
    "    # Look for explicit currency codes\n",
    "    for text in texts:\n",
    "        m = INLINE_CURRENCY_REGEX.search(text)\n",
    "        if m:\n",
    "            return (m.group(1) or m.group(2)).upper()\n",
    "\n",
    "    #Look for currency symbols\n",
    "    for text in texts:\n",
    "        if \"€\" in text:\n",
    "            return \"EUR\"\n",
    "        if \"£\" in text:\n",
    "            return \"GBP\"\n",
    "        if \"$\" in text:\n",
    "            return \"USD\"\n",
    "\n",
    "    return None\n",
    "\n",
    "currency_udf = udf(extract_currency, StringType())\n",
    "\n",
    "# =========================\n",
    "# ACCOUNT ID/NAME EXTRACTION\n",
    "# =========================\n",
    "\n",
    "ACCOUNT_KEYWORDS = [\n",
    "    \"account id\",\n",
    "    \"account id / group\",\n",
    "    \"account name\",\n",
    "    \"billing account\",\n",
    "    \"account:\",\n",
    "    \"customer\",\n",
    "    \"advertiser\",\n",
    "    \"werbekunde\"\n",
    "]\n",
    "# Hard-coded overrides for tricky invoices\n",
    "MANUAL_OVERRIDES = {\n",
    "    \"facebook\": \"951120803112976\",\n",
    "    \"derbysoft\": \"Jakala UK Ltd\"\n",
    "}\n",
    "\n",
    "\n",
    "def extract_advertising_account(elements):\n",
    "    if not elements:\n",
    "        return None\n",
    "\n",
    "    norm_elements = [\n",
    "        el if isinstance(el, dict) else el.asDict()\n",
    "        for el in elements\n",
    "    ]\n",
    "\n",
    "    # =========================\n",
    "    # META: Account Id / Group is split across table cells\n",
    "    # =========================\n",
    "    for el in norm_elements:\n",
    "        content = el.get(\"content\") or \"\"\n",
    "        if el.get(\"type\") == \"table\" and \"account id / group\" in content.lower():\n",
    "            soup = BeautifulSoup(content, \"html.parser\")\n",
    "            for tr in soup.find_all(\"tr\"):\n",
    "                tds = tr.find_all(\"td\")\n",
    "                if len(tds) == 2:\n",
    "                    label = tds[0].get_text(strip=True).lower()\n",
    "                    value = tds[1].get_text(strip=True)\n",
    "                    if \"account id / group\" in label:\n",
    "                        m = re.search(r\"\\b\\d{6,}\\b\", value)\n",
    "                        if m:\n",
    "                            return m.group(0)\n",
    "\n",
    "    # =========================\n",
    "    # GOOGLE ADS: dashed account id (e.g., 138-458-8188)\n",
    "    # =========================\n",
    "    for el in norm_elements:\n",
    "        content = el.get(\"content\") or \"\"\n",
    "        if \"account id\" in content.lower():\n",
    "            m = re.search(r\"\\b\\d{3}-\\d{3}-\\d{4}\\b\", content)\n",
    "            if m:\n",
    "                return m.group(0)\n",
    "    # ==========================\n",
    "    # MICROSOFT ADS account id\n",
    "    # =========================\n",
    "    BING_ACCOUNT_ID_LABELS = [\"kontonummer\", \"account number\", \"account id\"]\n",
    "    BING_ACCOUNT_ID_EXCLUDE_CONTENT = [\"swift\", \"iban\",\"bank\"]\n",
    "    BING_ACCOUNT_ID_REGEX = re.compile(r\"\\b[A-Z0-9]{6,12}\\b\")\n",
    "\n",
    "    for i, el in enumerate(norm_elements):\n",
    "        content = (el.get(\"content\") or \"\").strip().lower()\n",
    "        if el.get(\"type\") != \"text\":\n",
    "            continue\n",
    "\n",
    "        if any(lbl in content for lbl in BING_ACCOUNT_ID_LABELS):\n",
    "            # Look ahead a few elements (ordering is not guaranteed)\n",
    "            for j in range(i + 1, min(i + 4, len(norm_elements))):\n",
    "                candidate = (norm_elements[j].get(\"content\") or \"\").strip()\n",
    "                candidate_lower = candidate.lower()\n",
    "\n",
    "                if any(excl in candidate_lower for excl in BING_ACCOUNT_ID_EXCLUDE_CONTENT):\n",
    "                    continue\n",
    "\n",
    "            # Match candidate with regex\n",
    "                if BING_ACCOUNT_ID_REGEX.match(candidate):\n",
    "                    return candidate\n",
    "\n",
    "    # =========================\n",
    "    # Fallback: keyword + value in the same string\n",
    "    # =========================\n",
    "    for el in norm_elements:\n",
    "        content = el.get(\"content\") or \"\"\n",
    "        text_clean = \" \".join(content.split())\n",
    "        text_lower = text_clean.lower()\n",
    "\n",
    "        for kw in ACCOUNT_KEYWORDS:\n",
    "            if kw not in text_lower:\n",
    "                continue\n",
    "\n",
    "            m = re.search(\n",
    "                rf\"{re.escape(kw)}\\s*[:\\-]?\\s*([A-Za-z0-9&.,()'\\-/ ]{{3,80}})\",\n",
    "                text_clean,\n",
    "                flags=re.IGNORECASE\n",
    "            )\n",
    "            if m:\n",
    "                candidate = m.group(1).split(\"/\")[0].strip()\n",
    "                candidate_norm = candidate.lower().replace(\".\", \"\").replace(\",\", \"\")\n",
    "                if \"derbysoft\" in candidate_norm:\n",
    "                    continue\n",
    "                return candidate\n",
    "    # =========================\n",
    "    # MANUAL OVERRIDES\n",
    "    # =========================\n",
    "    for el in norm_elements:\n",
    "        text_lower = (el.get(\"content\") or \"\").lower()\n",
    "        for keyword, value in MANUAL_OVERRIDES.items():\n",
    "            if keyword in text_lower:\n",
    "                return value\n",
    "    return None\n",
    "\n",
    "advertising_account_udf = udf(extract_advertising_account, StringType())\n",
    "\n",
    "# =========================\n",
    "# ADVERT.COMPANY EXTRACTION\n",
    "# =========================\n",
    "\n",
    "VENDOR_PATTERNS = [\n",
    "    (\"Meta\", [\n",
    "        \"meta platforms\",\n",
    "        \"facebook\",\n",
    "        \"instagram\",\n",
    "        \"payment@fb.com\"\n",
    "    ]),\n",
    "    (\"Google Ads\", [\n",
    "        \"google ads\",\n",
    "        \"google ireland\",\n",
    "        \"google llc\",\n",
    "        \"adwords\"\n",
    "    ]),\n",
    "    (\"Microsoft Ads\", [\n",
    "        \"microsoft advertising\",\n",
    "        \"bing ads\",\n",
    "        \"microsoft ireland\"\n",
    "    ]),\n",
    "    (\"Derbysoft\", [\n",
    "        \"derbysoft\"\n",
    "    ])\n",
    "]\n",
    "\n",
    "\n",
    "def extract_advertising_company(elements):\n",
    "    if not elements:\n",
    "        return None\n",
    "\n",
    "    texts = []\n",
    "    for el in elements:\n",
    "        try:\n",
    "            text = el[\"content\"]\n",
    "        except Exception:\n",
    "            text = None\n",
    "\n",
    "        if text:\n",
    "            texts.append(text.lower())\n",
    "\n",
    "    full_text = \" \".join(texts)\n",
    "\n",
    "    for company, keywords in VENDOR_PATTERNS:\n",
    "        if any(k in full_text for k in keywords):\n",
    "            return company\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "advertising_company_udf = udf(extract_advertising_company, StringType())\n",
    "\n",
    "# =========================\n",
    "# AMOUNT NORMALIZATION\n",
    "# =========================\n",
    "def clean_amount(amt_raw):\n",
    "    if not amt_raw:\n",
    "        return None\n",
    "\n",
    "    # Removes any character that is not digit, dot, comma, or minus\n",
    "    amt_raw = re.sub(r\"[^\\d.,\\-]\", \"\", amt_raw)\n",
    "    # If comma is used as thousands separator and dot as decimal\n",
    "    if amt_raw.count(\",\") > 0 and amt_raw.count(\".\") == 1 and amt_raw.find(\",\") < amt_raw.find(\".\"):\n",
    "        amt_clean = amt_raw.replace(\",\", \"\")\n",
    "    # If dot is used as thousands separator and comma as decimal\n",
    "    elif amt_raw.count(\".\") > 0 and amt_raw.count(\",\") == 1 and amt_raw.find(\".\") < amt_raw.find(\",\"):\n",
    "        amt_clean = amt_raw.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    # If only comma is present, treat as decimal\n",
    "    elif amt_raw.count(\",\") == 1 and amt_raw.count(\".\") == 0:\n",
    "        amt_clean = amt_raw.replace(\",\", \".\")\n",
    "    # If only dot is present, treat as decimal\n",
    "    else:\n",
    "        amt_clean = amt_raw\n",
    "    try:\n",
    "        return round(float(amt_clean), 2)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# HTML ELEMENT EXTRACTION\n",
    "# =========================\n",
    "def extract_items_from_table_html(html, advertising_company=None):\n",
    "    if not html:\n",
    "        return []\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    items = []\n",
    "\n",
    "    # Filtering out rows with fee, vat, etc. in the description as an option\n",
    "    ROW_EXCLUDE_KEYWORDS = [\n",
    "        \"subtotal\",\n",
    "        \"grand total\",\n",
    "        \"total in\",\n",
    "        \"vat\",\n",
    "        \"tax\",\n",
    "    ]\n",
    "\n",
    "    ROW_OPTIONAL_EXCLUDE_KEYWORDS = [\n",
    "        \"fee\",\n",
    "        \"regulatory\"\n",
    "    ]\n",
    "\n",
    "    # Define keywords for fallback filtering; use only when headers are missing to pick up valid line items using kw-s\n",
    "    # ITEMS_KEYWORDS = [\"kempinski\"]\n",
    "\n",
    "    EMBEDDED_AMOUNT_REGEX = re.compile(\n",
    "        r\"(USD|EUR|GBP)\\s*([0-9,]+\\.\\d{2})\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    EXCLUDE_OPTIONAL_ROWS = True  # set to False if you want to keep fee rows\n",
    "\n",
    "    def should_exclude_row(description: str, amount: float, advertising_company: str) -> bool:\n",
    "        if not description:\n",
    "            return True\n",
    "\n",
    "        # Normalize description for comparison\n",
    "        def normalize(s):\n",
    "            return \" \".join(s.lower().replace(\",\", \".\").split())\n",
    "\n",
    "        desc_norm = normalize(description)\n",
    "        # desc_norm = \" \".join(description.lower().split())\n",
    "        # For Meta: only include rows with 'instagram' or 'kempinski'\n",
    "        if advertising_company == \"Meta\":\n",
    "            if \"instagram\" in desc_norm or \"kempinski\" in desc_norm:\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "        # Always exclude summary keywords\n",
    "        if any(k in desc_norm for k in ROW_EXCLUDE_KEYWORDS):\n",
    "            return True\n",
    "\n",
    "        # Optionally exclude fee / regulatory rows\n",
    "        if EXCLUDE_OPTIONAL_ROWS and any(k in desc_norm for k in ROW_OPTIONAL_EXCLUDE_KEYWORDS):\n",
    "            return True\n",
    "\n",
    "        # Exact description + amount exclusions\n",
    "        EXACT_EXCLUDE = [\n",
    "            (\"meta platforms ireland limited\", 181958.06),\n",
    "            (\"meta platforms ireland limited\", 0),\n",
    "            (\"acct name: meta platforms ireland limited\", 3),\n",
    "            (\"acct name: meta platforms ireland limited\", 218349.69),\n",
    "            (\"acct name: meta platforms ireland limited\", 9399006600000000.0),\n",
    "            (\"meta platforms ireland limited\", 0),\n",
    "            (\"bank of america europe dac\", 0),\n",
    "            (\"bank of america europe dac\", 181958.06),\n",
    "            (\"2 park place\", 0),\n",
    "            (\"2 park place\", 181958.06),\n",
    "            (\"account number (iban: ie93 bofa 9900 6154 8780 17\", 218349.69),\n",
    "            (\"account number (iban: ie93 bofa 9900 6154 8780 17\", 31758.26),\n",
    "            (\"account number iban: ie93 bofa 9900 6154 8780 17\", 218349.69),\n",
    "            (\"account number: iban: ie93 bofa 9900 6154 8780 17\", 218349.69),\n",
    "            (\"merrion road\", 0),\n",
    "            (\"merrion road\", 181958.06),\n",
    "            (\"merrion road\", 22),\n",
    "            (\"dublin 2\", 9399006600000000.0),\n",
    "            (\"dublin 4, d04 x2k5\", 36391.62),\n",
    "            (\"dublin 4, d04 x2k5\", 0),\n",
    "            (\"dublin 2\", 36391.62),\n",
    "            (\"dublin 2\", 9399006600000000.0),\n",
    "            (\"hatch street\", 36391.62),\n",
    "            (\"hatch street\", 0),\n",
    "            (\"ireland\", 218349.69),\n",
    "            (\"ireland\", 9399006600000000.0),\n",
    "            (\"ireland\", 36391.62),\n",
    "            (\"ireland\", 20),\n",
    "            (\"ireland\", 0),\n",
    "            (\"ie9692928f\", 9399006600000000.0),\n",
    "            (\"payment@fb.com\", None),\n",
    "            (\"account number iban: ie93 bofa 9900 6154 8780 17\", 31758.26),\n",
    "            (\"swift code: bofaie3x\", 31758.26),\n",
    "            (\"swift code: bofaie3x\", 218349.69),\n",
    "            (\"swift code (international transfer): bofaie3x\", 218349.69),\n",
    "            (\"swift code (international transfer): bofaie3x\", 31758.26),\n",
    "        ]\n",
    "        for ex_desc, ex_amt in EXACT_EXCLUDE:\n",
    "            ex_desc_norm = normalize(ex_desc)\n",
    "            if ex_desc_norm in desc_norm and (ex_amt is None or abs(ex_amt - amount) < 0.01):\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    header_indices = None\n",
    "    HOTEL_DESC_KEYWORDS = [\n",
    "        \"hotelname\",\n",
    "        \"hotel name\",\n",
    "        \"property\",\n",
    "        \"propertyname\"\n",
    "        ]\n",
    "    DESC_KEYWORDS = [\n",
    "            \"description\", \"item\", \"lineitem\", \"product\", \"service\",\n",
    "            \"campaign\", \"ad\", \"details\",\"beschreibung\"\n",
    "        ]\n",
    "    AMT_KEYWORDS = [\n",
    "            \"amount\", \"total\", \"cost\", \"price\", \"charge\", \"net\", \"subtotal\",\"gesamt\"\n",
    "        ]\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        rows = table.find_all(\"tr\")\n",
    "        if not rows or len(rows) < 2:\n",
    "            continue\n",
    "\n",
    "        merged_rows = rows\n",
    "    # =========================\n",
    "        # MS ADS ROW EXTRACTION\n",
    "        # =========================\n",
    "        if advertising_company == \"Microsoft Ads\":\n",
    "            merged_rows = []\n",
    "            i = 0\n",
    "            while i < len(rows):\n",
    "                tr = rows[i]\n",
    "                tds = tr.find_all(\"td\")\n",
    "\n",
    "                # Extract description and amount from current row\n",
    "                desc = \" \".join([td.get_text(strip=True) for td in tds])\n",
    "                amt = None\n",
    "                for td in tds:\n",
    "                    m = re.search(r\"-?[0-9,]+\\.\\d\", td.get_text())\n",
    "                    if m:\n",
    "                        amt = float(m.group().replace(\",\", \"\"))\n",
    "\n",
    "                # Case 1: Empty amount, next row is Gutschrift with negative amount\n",
    "                if (amt is None or abs(amt) < 0.01) and i + 1 < len(rows):\n",
    "                    next_tr = rows[i + 1]\n",
    "                    next_tds = next_tr.find_all(\"td\")\n",
    "                    next_desc = \" \".join([td.get_text(strip=True) for td in next_tds])\n",
    "                    next_amt = None\n",
    "                    for td in next_tds:\n",
    "                        m = re.search(r\"-?[0-9,]+\\.\\d+\", td.get_text())\n",
    "                        if m:\n",
    "                            next_amt = float(m.group().replace(\",\", \"\"))\n",
    "                    if \"gutschrift\" in next_desc.lower() and next_amt is not None and next_amt < 0:\n",
    "                        # Use Gutschrift row's description and amount only\n",
    "                        next_tr.merged_text = next_desc\n",
    "                        next_tr.merged_amount = next_amt\n",
    "                        merged_rows.append(next_tr)\n",
    "                        i += 2\n",
    "                        continue\n",
    "                \"\"\"\n",
    "                # Case 2: Current row has amount, next row has same description and negative amount\n",
    "                if amt is not None and amt > 0 and i + 1 < len(rows):\n",
    "                    next_tr = rows[i + 1]\n",
    "                    next_tds = next_tr.find_all(\"td\")\n",
    "                    next_desc_raw = \" \".join([td.get_text(strip=True) for td in next_tds])\n",
    "                    next_amt = None\n",
    "                    for td in next_tds:\n",
    "                        m = re.search(r\"-?[0-9,]+\\\\.\\\\d+\", td.get_text())\n",
    "                        if m:\n",
    "                            next_amt = float(m.group().replace(\",\", \"\"))\n",
    "                    # If next row is Gutschrift or has same description and negative amount\n",
    "                    if (\n",
    "                        (next_desc_raw == desc or \"gutschrift\" in next_desc_raw.lower())\n",
    "                        and next_amt is not None and next_amt < 0\n",
    "                    ):\n",
    "                        # Optionally, concatenate Gutschrift description\n",
    "                        if \"gutschrift\" in next_desc_raw.lower():\n",
    "                            desc = desc + \" \" + next_desc_raw\n",
    "                        tr.merged_text = desc\n",
    "                        tr.merged_amount = amt\n",
    "                        merged_rows.append(tr)\n",
    "                        # Add the negative row as a separate item\n",
    "                        next_tr.merged_text = next_desc_raw\n",
    "                        next_tr.merged_amount = next_amt\n",
    "                        merged_rows.append(next_tr)\n",
    "                        i += 2\n",
    "                        continue\n",
    "                \"\"\"\n",
    "                # Otherwise, keep the row as is\n",
    "                tr.merged_text = desc\n",
    "                tr.merged_amount = amt\n",
    "                merged_rows.append(tr)\n",
    "                i += 1\n",
    "        if merged_rows is not None:\n",
    "            rows = merged_rows\n",
    "\n",
    "\n",
    "        # GOOGLE ADS ROW EXTRACTION (stream-based robust Invalid activity handling)\n",
    "        # =========================\n",
    "        if advertising_company == \"Google Ads\":\n",
    "            merged_rows = []\n",
    "            i = 0\n",
    "            while i < len(rows):\n",
    "                tr = rows[i]\n",
    "                tds = tr.find_all(\"td\")\n",
    "                desc = tds[0].get_text(strip=True) if tds else \"\"\n",
    "                amt = clean_amount(tds[-1].get_text(strip=True)) if tds else None\n",
    "\n",
    "                # Start merge: accumulate description until we hit an amount\n",
    "                merged_desc = desc\n",
    "                merged_amt = amt\n",
    "                j = i + 1\n",
    "                while j < len(rows):\n",
    "                    next_tr = rows[j]\n",
    "                    next_tds = next_tr.find_all(\"td\")\n",
    "                    next_desc = next_tds[0].get_text(strip=True) if next_tds else \"\"\n",
    "                    next_amt = clean_amount(next_tds[-1].get_text(strip=True)) if next_tds else None\n",
    "\n",
    "                    # Heuristic: continuation row has empty amount OR amount matches first row\n",
    "                    if (next_amt is None) or (merged_amt is not None and abs(next_amt) < 0.01):\n",
    "                        merged_desc += \" \" + next_desc\n",
    "                        # pick the amount if current merged_amt is None\n",
    "                        if merged_amt is None and next_amt is not None:\n",
    "                            merged_amt = next_amt\n",
    "                        j += 1\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                # Append merged row\n",
    "                tr.merged_text = merged_desc\n",
    "                tr.merged_amount = merged_amt\n",
    "                merged_rows.append(tr)\n",
    "                i = j  # skip merged rows\n",
    "\n",
    "            rows = merged_rows\n",
    "\n",
    "\n",
    "        # =========================\n",
    "        # END\n",
    "        # =========================\n",
    "        # Find header row: row with most cells\n",
    "        header_row = next((r for r in rows if r.find(\"th\")), None)\n",
    "        desc_idx = amt_idx = None\n",
    "\n",
    "        if header_row:\n",
    "            headers = [\n",
    "                cell.get_text(strip=True).lower().replace(\" \", \"\").replace(\"_\", \"\")\n",
    "                for cell in header_row.find_all([\"th\", \"td\"])\n",
    "            ]\n",
    "\n",
    "            desc_idx = next(\n",
    "                (i for i, h in enumerate(headers) if any(k in h for k in HOTEL_DESC_KEYWORDS)),\n",
    "                None\n",
    "            )\n",
    "            if desc_idx is None:\n",
    "                desc_idx = next(\n",
    "                    (i for i, h in enumerate(headers) if any(k in h for k in DESC_KEYWORDS)),\n",
    "                    None\n",
    "                )\n",
    "\n",
    "            amt_idx = next(\n",
    "                (i for i, h in enumerate(headers) if any(k in h for k in AMT_KEYWORDS)),\n",
    "                None\n",
    "            )\n",
    "\n",
    "            if desc_idx is not None:\n",
    "                header_indices = (desc_idx, amt_idx)\n",
    "\n",
    "        if header_indices is None:\n",
    "            continue\n",
    "\n",
    "        desc_idx, amt_idx = header_indices\n",
    "\n",
    "        for tr in rows[1:]:\n",
    "            tds = tr.find_all(\"td\")\n",
    "\n",
    "            # Use merged text/amount if available\n",
    "            desc = getattr(tr, \"merged_text\", None)\n",
    "\n",
    "            if not desc and len(tds) > desc_idx:\n",
    "                desc = tds[desc_idx].get_text(strip=True)\n",
    "\n",
    "            amt = getattr(tr, \"merged_amount\", None)\n",
    "            # Normal amount column\n",
    "            if amt is None and amt_idx is not None and len(tds) > amt_idx:\n",
    "                amt = clean_amount(tds[amt_idx].get_text(strip=True))\n",
    "\n",
    "            # Embedded amount fallback\n",
    "            if amt is None:\n",
    "                for td in tds:\n",
    "                    m = EMBEDDED_AMOUNT_REGEX.search(td.get_text())\n",
    "                    if m:\n",
    "                        amt = clean_amount(m.group(2))\n",
    "                        break\n",
    "\n",
    "            if amt is None or not desc:\n",
    "                continue\n",
    "\n",
    "            # filtering happens based on the exclude descriptions function above\n",
    "            if should_exclude_row(desc,amt, advertising_company):\n",
    "                continue\n",
    "            items.append({\n",
    "                \"Description\": desc,\n",
    "                \"Amount\": amt\n",
    "            })\n",
    "    return items\n",
    "\n",
    "items_schema = ArrayType(\n",
    "    StructType([\n",
    "        StructField(\"Description\", StringType()),\n",
    "        StructField(\"Amount\", FloatType())\n",
    "    ])\n",
    ")\n",
    "\n",
    "items_udf = udf(extract_items_from_table_html, items_schema)\n",
    "\n",
    "# =========================\n",
    "# SPARK DATAFRAMES\n",
    "# =========================\n",
    "\n",
    "df = spark.read.format(\"binaryFile\").load(\"/Volumes/workspace/default/invoices_highres/*.pdf\")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"parsed\",\n",
    "    expr(\"ai_parse_document(content, map('version', '2.0'))\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"elements_struct\",\n",
    "    expr(\"\"\"\n",
    "        try_cast(\n",
    "            parsed:document:elements\n",
    "            AS ARRAY<STRUCT<content:STRING,type:STRING>>\n",
    "        )\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"invoice_number\",\n",
    "    invoice_udf(col(\"elements_struct\"))\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"advertising_company\",\n",
    "    advertising_company_udf(col(\"elements_struct\"))\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"advertising_account\",\n",
    "    advertising_account_udf(col(\"elements_struct\"))\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"currency\",\n",
    "    currency_udf(col(\"elements_struct\"))\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"table_html\",\n",
    "    expr(\"\"\"\n",
    "        concat_ws(\n",
    "            '\\n\\n',\n",
    "            transform(\n",
    "                filter(\n",
    "                    try_cast(parsed:document:elements AS ARRAY<VARIANT>),\n",
    "                    e -> cast(e:type as string) = 'table'\n",
    "                ),\n",
    "                e -> cast(e:content as string)\n",
    "            )\n",
    "        )\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "df_items = df.withColumn(\"items\", items_udf(\"table_html\"))\n",
    "\n",
    "df_flat = df_items.select(\n",
    "    \"path\",\n",
    "    \"invoice_number\",\n",
    "    \"advertising_company\",\n",
    "    \"advertising_account\",\n",
    "    \"currency\",\n",
    "    explode(\"items\").alias(\"item\")\n",
    ").select(\n",
    "    \"path\",\n",
    "    \"invoice_number\",\n",
    "    \"advertising_company\",\n",
    "    \"advertising_account\",\n",
    "    \"currency\",\n",
    "    \"item.Description\",\n",
    "    \"item.Amount\"\n",
    ")\n",
    "\n",
    "display(df_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54989f36-0748-4e0c-aae8-782585041914",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Explore how the PDFs get parsed**<br>Retrieve the path, parsed result (raw), text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1553f50-5cb4-400f-b8cf-4905fae9d978",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"path\":573},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1768328026511}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "View parsed results: path, raw, text"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH parsed_documents AS (\n",
    "  SELECT\n",
    "    path,\n",
    "    ai_parse_document(\n",
    "      content,\n",
    "      map('version', '2.0')\n",
    "    ) AS parsed\n",
    "  FROM READ_FILES(\n",
    "    '/Volumes/workspace/default/invoices_highres/*.{pdf}',\n",
    "    format => 'binaryFile'\n",
    "  )\n",
    "), parsed_text AS (\n",
    "  SELECT\n",
    "    path,\n",
    "    parsed,\n",
    "    concat_ws(\n",
    "      '\\n\\n',\n",
    "      transform(\n",
    "        try_cast(parsed:document:elements AS ARRAY<VARIANT>),\n",
    "        element -> try_cast(element:content AS STRING)\n",
    "      )\n",
    "    ) AS parsed_text\n",
    "  FROM parsed_documents\n",
    "  WHERE try_cast(parsed:error_status AS STRING) IS NULL\n",
    ")\n",
    "SELECT path, parsed, parsed_text FROM parsed_text;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b71c010b-8965-4f08-b46d-07c82ef3ff26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2a26f37-6084-4936-95a6-7a0d694eb711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Extract the result using the Output window**<br>Download as CSV, Excel, Copy results to clipboard, add to notebook dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ed8f56a-a5c9-4a43-bc3e-006bc32a814b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Perform further transformations to the DF as necessary**<br>E.g., Drop null values, drop duplicates, filter results, perform computations and aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9e8b7e9-7e6d-4bbd-8552-c04c8d16370a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Write the DF to a table for further querying / transformation**<br> Run SQL commands to further transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "959b21ef-2789-4f50-bedb-4d4f293e3de4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save the DF as a table"
    }
   },
   "outputs": [],
   "source": [
    "# Writes the dataframe to a table\n",
    "df_flat.write.mode(\"overwrite\").saveAsTable(\"CATALOG.SCHEMA.TABLE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03b05b3f-637b-45d9-bbcc-4fe244815fca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Send the output as a file attachment via email**<br>Install and configure Databricks CLI; create and use a Databricks secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1aa6dd48-29b0-4d98-8faf-50a82b6c835a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Retrieve the app password"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve Gmail app password from Databricks secrets\n",
    "# This securely loads your app password for use in the email function\n",
    "\n",
    "gmail_app_password = dbutils.secrets.get(scope=\"gmail\", key=\"app_password\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "444add26-04c6-4a61-8a0a-d8dbac1d5095",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save the DF in a temp directory"
    }
   },
   "outputs": [],
   "source": [
    "# Save the output DataFrame to a CSV file for email attachment\n",
    "# This ensures the file is accessible by Python's open()\n",
    "\n",
    "df_flat.toPandas().to_csv('/tmp/invoice_items.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25d36d5f-80d0-4ac8-9230-b680ab9f2e22",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Send an email with the file attached"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEPS\n",
    "Create an app password for your email vendor (microsoft, google)\n",
    "Generate a token in Databricks (go to the account settings)\n",
    "Open command line to configure databricks\n",
    "\n",
    "    EXAMPLE (gmail):\n",
    "    pip install databricks-cli\n",
    "\n",
    "    databricks --version\n",
    "\n",
    "    databricks configure --token \n",
    "    (provide the Hostname, the token generated earlier; input your databricks username and the email app password)\n",
    "\n",
    "    databricks secrets create-scope --scope gmail\n",
    "    databricks secrets put --scope gmail --key gmail_app_password\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "def send_email_with_attachment(to_email, subject, body, file_path, password):\n",
    "    msg = EmailMessage()\n",
    "    msg['From'] = 'SENDER.@gmail.com'\n",
    "    msg['To'] = to_email\n",
    "    msg['Subject'] = subject\n",
    "    msg.set_content(body)\n",
    "\n",
    "    with open('/tmp/invoice_items.csv', 'rb') as f:\n",
    "        msg.add_attachment(\n",
    "            f.read(),\n",
    "            maintype='application',\n",
    "            subtype='octet-stream',\n",
    "            filename='invoice_items.csv'\n",
    "        )\n",
    "\n",
    "    # Connect to Gmail SMTP\n",
    "    with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "        server.starttls()\n",
    "        server.login('SENDER@gmail.com', password)\n",
    "        server.send_message(msg)\n",
    "        print(\"Email sent successfully!\")\n",
    "\n",
    "# Call the function\n",
    "send_email_with_attachment(\n",
    "    to_email='RECIPIENT@gmail.com',\n",
    "    subject='Invoice Items Export',\n",
    "    body='Please find the invoice items attached.',\n",
    "    file_path='/tmp/invoice_items.csv',\n",
    "    password=gmail_app_password\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2260755870428460,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "pdf_invoice_parser_15012026",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
